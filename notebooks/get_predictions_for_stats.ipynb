{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from eyemind.trainer.loops import KFoldLoop\n",
    "import eyemind\n",
    "from eyemind.models.transformers import InformerEncoderDecoderModel, InformerEncoderFixationModel, InformerMultiTaskEncoderDecoder\n",
    "from eyemind.dataloading.informer_data import InformerDataModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "def fixation_image(pred,target, title=\"Fixation Identification\"):\n",
    "    sl = len(pred)\n",
    "    fixation_labels = torch.cat((pred.expand(sl//2,sl),target.expand(sl//2,sl)))\n",
    "    plt.imshow(fixation_labels, extent=[0, len(fixation_labels[1]),0, 100], cmap='Greys')\n",
    "    # plt.xticks(np.arange(0, len(fixation_labels), 1), [])\n",
    "    plt.yticks([])\n",
    "    # plt.grid(True, axis='x', lw=1, c='black')\n",
    "    # plt.tick_params(axis='x', length=0)\n",
    "    plt.title(title)\n",
    "    black = mpatches.Patch(color='black', label='Fixation')\n",
    "    white = mpatches.Patch(color='white', label='Saccade')\n",
    "    plt.legend(handles=[black, white],bbox_to_anchor=(1.15, 1), loc='upper right')\n",
    "    plt.xlabel(\"Time Steps (100 steps ~ 1.7s)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/dg/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Global seed set to 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "length of batch: 4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "InformerMultiTaskEncoderDecoder.forward() missing 1 required positional argument: 'x_dec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength of batch: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(batch)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m preds \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpreds: \u001b[39m\u001b[39m{\u001b[39;00mpreds\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dg/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: InformerMultiTaskEncoderDecoder.forward() missing 1 required positional argument: 'x_dec'"
     ]
    }
   ],
   "source": [
    "repodir = os.path.dirname(os.path.dirname(eyemind.__file__))\n",
    "\n",
    "for fold in [0, 1, 2, 3]:\n",
    "    save_dir = f\"{repodir}/lightning_logs/informer_pretraining_seed21/fold{fold}/\"\n",
    "    config_path=os.path.join(save_dir,\"config.yaml\")\n",
    "    ckpt_path = os.path.join(save_dir,\"checkpoints\",\"last.ckpt\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    model = InformerMultiTaskEncoderDecoder.load_from_checkpoint(ckpt_path,\n",
    "                                                    encoder_weights_path=None)\n",
    "    # model.tasks=[\"fi\"]\n",
    "    model.eval()\n",
    "\n",
    "    # print(model.tasks)\n",
    "    # trainer = Trainer(**config[\"trainer\"])\n",
    "    seed_everything(config[\"seed_everything\"], workers=True)\n",
    "    data_dir = os.path.join(repodir,config[\"data\"][\"data_dir\"])\n",
    "    label_file = os.path.join(repodir,config[\"data\"][\"label_filepath\"])\n",
    "    config[\"data\"][\"data_dir\"]=data_dir\n",
    "    config[\"data\"][\"label_filepath\"]=label_file\n",
    "    \n",
    "    datamodule = InformerDataModule(**config[\"data\"])\n",
    "    datamodule.setup()\n",
    "\n",
    "    test_dl = datamodule.get_dataloader(datamodule.test_dataset)\n",
    "    for i,batch in enumerate(test_dl):\n",
    "        print(f\"batch: {i}\")\n",
    "        print(f\"length of batch: {len(batch)}\")\n",
    "        preds = model(batch)\n",
    "        print(f\"preds: {preds.shape}\")\n",
    "        if i==1:\n",
    "            break\n",
    "        fixation_preds = preds[\"fi\"]\n",
    "        fixation_targets = batch[1]\n",
    "        fixation_image(fixation_preds[1], fixation_targets[1], \"Fixation Identification - Informer\")\n",
    "    # pc_targets = batch[0][:4,-100:]\n",
    "    # rc_targets = batch[0][:4,:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "InformerMultiTaskEncoderDecoder.forward() missing 1 required positional argument: 'x_dec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(logits\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[39m#     601 def _step(self, batch, batch_idx, step_type):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#     602     try:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# --> 603         X, fix_y, X2, cl_y = batch\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# preds = model.predict(batch, i) \u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# # AttributeError: 'InformerMultiTaskEncoderDecoder' object has no attribute 'predict'\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: InformerMultiTaskEncoderDecoder.forward() missing 1 required positional argument: 'x_dec'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    logits = model.forward(batch[0])\n",
    "    print(logits.shape)\n",
    "#     601 def _step(self, batch, batch_idx, step_type):\n",
    "#     602     try:\n",
    "# --> 603         X, fix_y, X2, cl_y = batch\n",
    "#     604     except ValueError as e:\n",
    "#     605         print(f\"{batch}\")\n",
    "# ValueError: not enough values to unpack (expected 4, got 2)\n",
    "\n",
    "# preds = model(batch[0], batch[1], i) \n",
    "# # 'InformerMultiTaskEncoderDecoder' object has no attribute 'decoder'\n",
    "\n",
    "# preds = model.predict_step(batch[0],batch[1], i) \n",
    "# # TypeError: InformerMultiTaskEncoderDecoder.forward() missing 1 required positional argument: 'x_dec'\n",
    "\n",
    "# preds = model.predict(batch, i) \n",
    "# # AttributeError: 'InformerMultiTaskEncoderDecoder' object has no attribute 'predict'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InformerMultiTaskEncoderDecoder' object has no attribute 'decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch[\u001b[39m0\u001b[39;49m],batch[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpreds: \u001b[39m\u001b[39m{\u001b[39;00mpreds\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Dropbox (Emotive Computing)/EML Rosy/DeepGaze/eyemind/models/transformers.py:589\u001b[0m, in \u001b[0;36mInformerMultiTaskEncoderDecoder.forward\u001b[0;34m(self, x_enc, x_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     enc_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x_enc, enc_self_mask)\n\u001b[0;32m--> 589\u001b[0m     dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(enc_out, x_dec, dec_self_mask, dec_enc_mask)\n\u001b[1;32m    590\u001b[0m     \u001b[39mreturn\u001b[39;00m dec_out\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/dg/lib/python3.10/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InformerMultiTaskEncoderDecoder' object has no attribute 'decoder'"
     ]
    }
   ],
   "source": [
    "preds = model.forward(batch[0],batch[1])\n",
    "print(f\"preds: {preds.shape}\")\n",
    "fixation_preds = preds[\"fi\"]\n",
    "fixation_targets = batch[1]\n",
    "fixation_image(fixation_preds[1], fixation_targets[1], \"Fixation Identification - Informer\")\n",
    "# pc_targets = batch[0][:4,-100:]\n",
    "# rc_targets = batch[0][:4,:-100]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "try loading encoder and fi decoder separately\n",
    "try modifying train loop to store the preds per batch\n",
    "within loop, get batch and run thru 2 models - ensure ssame random subsequence chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COmprehension: Rote X\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
