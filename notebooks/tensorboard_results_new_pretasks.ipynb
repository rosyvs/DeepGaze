{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tbparse import SummaryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE='new_multitask_informer' \n",
    "\n",
    "SAVE_PATH = f\"../results/{MODEL_TYPE}_results.md\"\n",
    "SEED=21\n",
    "OVERWRITE=True\n",
    "if OVERWRITE:\n",
    "     open(SAVE_PATH, 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_results_from_eventfile(dirpath, metrics, SAVE_PATH=\"\", title=\"\", select=\"latest\"):\n",
    "    # select = \"latest\", or \"lowest\" or \"highest\"\n",
    "    reader = SummaryReader(dirpath, pivot=False, extra_columns={'dir_name'})\n",
    "    df = reader.scalars\n",
    "    df = df.rename(columns={\"tag\": \"metric\", \"dir_name\": \"fold\"})\n",
    "    grouped = df.groupby([\"fold\",\"metric\"])\n",
    "    # ['step'].max().reset_index() # this is choosing the max AUROC but we want the latest!!\n",
    "    if select=='latest':\n",
    "        df = df.loc[grouped['step'].idxmax()].reset_index(drop=True)\n",
    "    elif select=='highest':\n",
    "        df = df.loc[grouped['value'].idxmax()].reset_index(drop=True)\n",
    "    elif select=='lowest':\n",
    "        df = df.loc[grouped['value'].idxmin()].reset_index(drop=True)\n",
    "    \n",
    "    df = df[df[\"metric\"].isin(metrics)].set_index([\"fold\"]).sort_values(\"metric\").reset_index()\n",
    "\n",
    "    res = df.pivot(index='fold', columns='metric', values='value')#.rename_axis(columns=None)\n",
    "    if SAVE_PATH:\n",
    "        with open(SAVE_PATH,'a') as f:\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(title)\n",
    "            f.write(\"\\n\")\n",
    "        res.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=True,floatfmt='.3f')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get pretraining task val metrics \n",
    "tasks=['fm','cl','pc','rc']\n",
    "metric_names=['FM: AUPRC','CL: Accuracy','PC: MSE (deg)','RC: MSE (deg)']\n",
    "metric_select=['highest','highest','lowest','lowest'] # which value to use when multiple checkpoints avail\n",
    "varname = 'val_{task}_metric'\n",
    "metrics=[varname.format(**locals()) for task in tasks]\n",
    "\n",
    "pretrain_summary=[]\n",
    "for i,metric in enumerate(metrics):\n",
    "    name=metric_names[i]\n",
    "    res=get_metric_results_from_eventfile(f\"../lightning_logs/{MODEL_TYPE}_pretraining_seed{SEED}\", [metric], SAVE_PATH, title=name, select=\"latest\")\n",
    "    pretrain_summary.append({\"metric\":name, \n",
    "                       \"mean\": res[[metric]].mean().item(),\n",
    "                       \"min\": res[[metric]].min().item(),\n",
    "                       \"max\": res[[metric]].max().item()\n",
    "                       })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "tit=\"Pretraining validation metrics: summarized\"\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(tit)\n",
    "    f.write(\"\\n\")\n",
    "tb = pd.DataFrame.from_records(pretrain_summary)\n",
    "tb.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=False,floatfmt='.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Rote_X', 'Rote_Y', \"Rote_Z\", \"Rote_D\",\n",
    "          'Inference_X', \"Inference_Y\",\"Inference_Z\", \"Inference_D\", \n",
    "          \"Deep_X\", \"Deep_Z\",\n",
    "          \"MW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"train_auroc\", \"val_auroc\", \"train_accuracy_epoch\", \"val_accuracy_epoch\"]\n",
    "val_aurocs = []\n",
    "for label in labels:\n",
    "    tit=f\"# {label}\"\n",
    "    with open(SAVE_PATH, \"a\") as f:\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(tit)\n",
    "        f.write(\"\\n\")\n",
    "    res=get_metric_results_from_eventfile(f\"../lightning_logs/{MODEL_TYPE}_{label}\", metrics, SAVE_PATH, select=\"highest\")\n",
    "    res['label']=label\n",
    "    val_aurocs.append({\"label\":label, \n",
    "                       \"mean AUROC\": res[['val_auroc']].mean().item(),\n",
    "                       \"min AUROC\": res[['val_auroc']].min().item(),\n",
    "                       \"max AUROC\": res[['val_auroc']].max().item()\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit=\"Held-out AUROCs\"\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(tit)\n",
    "    f.write(\"\\n\")\n",
    "tb = pd.DataFrame.from_records(val_aurocs)\n",
    "tb.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=False,floatfmt='.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence lens\n",
    "seqlens=[125, 250]\n",
    "folds=range(4)\n",
    "# Get pretraining task val metrics \n",
    "tasks=['fi','cl','pc','rc']\n",
    "metric_names=['FI: AUROC','CL: Accuracy','PC: MSE (deg)','RC: MSE (deg)']\n",
    "metric_select=['highest','highest','lowest','lowest'] # which value to use when multiple checkpoints avail\n",
    "varname = 'val_{task}_metric'\n",
    "metrics=[varname.format(**locals()) for task in tasks]\n",
    "\n",
    "seqlen_summary=[]\n",
    "for l in seqlens:\n",
    "    THISLEN={\"sequence length\": l}\n",
    "    for i,metric in enumerate(metrics):\n",
    "        name=metric_names[i]\n",
    "        per_fold=[]\n",
    "        for f in folds:\n",
    "            res=get_metric_results_from_eventfile(f\"../lightning_logs/{MODEL_TYPE}_pre_seqlen_seed{SEED}/fold{f}seqlen{l}\", [metric],  title=name, select=\"latest\")\n",
    "            per_fold.append(res[metric].item())\n",
    "        THISLEN[name]=sum(per_fold)/len(per_fold)\n",
    "    seqlen_summary.append(THISLEN)\n",
    "        \n",
    "# merge with pretraining_summary\n",
    "pretrain_means={\"sequence length\": 500}\n",
    "for entry in pretrain_summary:\n",
    "    pretrain_means[entry['metric']]=entry['mean']\n",
    "\n",
    "seqlen_summary.append(pretrain_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "tit=\"GRU pretraining by sequence length\"\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(tit)\n",
    "    f.write(\"\\n\")\n",
    "tb = pd.DataFrame.from_records(seqlen_summary)\n",
    "tb.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=False,floatfmt='.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.387425422668457"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[metric].item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyemind_arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1499b27fd6353fe811f6c3b1d5c11b5c4e6658fe4f557f45649495283ca3391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
