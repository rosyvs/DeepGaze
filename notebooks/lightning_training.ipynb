{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import obf functionality\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"../../OBF\").resolve()))\n",
    "\n",
    "from obf.model import ae\n",
    "from obf.model import creator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyemind.dataloading.load_dataset import limit_sequence_len, get_label_mapper, get_filenames_for_dataset, create_filename_col, get_stratified_group_splits\n",
    "from eyemind.dataloading.gaze_data import GazeDataModule\n",
    "from eyemind.models.classifier import EncoderClassifierModel\n",
    "# from eyemind.models import creator\n",
    "# from eyemind.models import ae \n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from pytorch_lightning import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"/Users/rickgentry/emotive_lab/eyemind/data/preprocessed/output\")\n",
    "label_filepath = Path(\"/Users/rickgentry/emotive_lab/eyemind/data/EML1_pageLevel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labels and create id\n",
    "label_df = pd.read_csv(label_filepath)\n",
    "label_df = create_filename_col(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantID</th>\n",
       "      <th>Text</th>\n",
       "      <th>PageNum</th>\n",
       "      <th>datetime</th>\n",
       "      <th>unix_start</th>\n",
       "      <th>unix_end</th>\n",
       "      <th>readtime</th>\n",
       "      <th>MW</th>\n",
       "      <th>SVT</th>\n",
       "      <th>Rote_X</th>\n",
       "      <th>Inference_X</th>\n",
       "      <th>Deep_X</th>\n",
       "      <th>Rote_Y</th>\n",
       "      <th>Inference_Y</th>\n",
       "      <th>Rote_Z</th>\n",
       "      <th>Inference_Z</th>\n",
       "      <th>Deep_Z</th>\n",
       "      <th>Rote_D</th>\n",
       "      <th>Inference_D</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EML1_001</td>\n",
       "      <td>Bias</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_001-Bias2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EML1_001</td>\n",
       "      <td>Bias</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_001-Bias6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EML1_001</td>\n",
       "      <td>CausalClaims</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_001-CausalClaims2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EML1_001</td>\n",
       "      <td>CausalClaims</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_001-CausalClaims8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EML1_001</td>\n",
       "      <td>Hypotheses</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_001-Hypotheses1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>EML1_167</td>\n",
       "      <td>Hypotheses</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_167-Hypotheses8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>EML1_167</td>\n",
       "      <td>Validity</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_167-Validity1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>EML1_167</td>\n",
       "      <td>Validity</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_167-Validity7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>EML1_167</td>\n",
       "      <td>Variables</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_167-Variables5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>EML1_167</td>\n",
       "      <td>Variables</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EML1_167-Variables8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1636 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ParticipantID          Text  PageNum datetime  unix_start  unix_end  \\\n",
       "2         EML1_001          Bias        3      NaN         NaN       NaN   \n",
       "6         EML1_001          Bias        7      NaN         NaN       NaN   \n",
       "12        EML1_001  CausalClaims        3      NaN         NaN       NaN   \n",
       "18        EML1_001  CausalClaims        9      NaN         NaN       NaN   \n",
       "20        EML1_001    Hypotheses        2      NaN         NaN       NaN   \n",
       "...            ...           ...      ...      ...         ...       ...   \n",
       "7859      EML1_167    Hypotheses        9      NaN         NaN       NaN   \n",
       "7860      EML1_167      Validity        2      NaN         NaN       NaN   \n",
       "7864      EML1_167      Validity        8      NaN         NaN       NaN   \n",
       "7869      EML1_167     Variables        6      NaN         NaN       NaN   \n",
       "7871      EML1_167     Variables        9      NaN         NaN       NaN   \n",
       "\n",
       "      readtime   MW  SVT  Rote_X  Inference_X  Deep_X  Rote_Y  Inference_Y  \\\n",
       "2       33.862  1.0  1.0     1.0          1.0     1.0     NaN          NaN   \n",
       "6       23.788  0.0  1.0     1.0          1.0     1.0     NaN          NaN   \n",
       "12      26.138  1.0  0.0     1.0          1.0     1.0     NaN          NaN   \n",
       "18      17.016  1.0  0.0     0.0          1.0     1.0     NaN          NaN   \n",
       "20         NaN  1.0  1.0     1.0          1.0     1.0     NaN          NaN   \n",
       "...        ...  ...  ...     ...          ...     ...     ...          ...   \n",
       "7859       NaN  1.0  1.0     0.0          0.0     0.0     NaN          NaN   \n",
       "7860       NaN  1.0  1.0     1.0          1.0     0.0     NaN          NaN   \n",
       "7864       NaN  1.0  0.0     0.0          1.0     0.0     NaN          NaN   \n",
       "7869       NaN  1.0  1.0     0.0          0.0     1.0     NaN          NaN   \n",
       "7871       NaN  1.0  0.0     0.0          0.0     1.0     NaN          NaN   \n",
       "\n",
       "      Rote_Z  Inference_Z  Deep_Z  Rote_D  Inference_D                filename  \n",
       "2        NaN          NaN     NaN     NaN          NaN          EML1_001-Bias2  \n",
       "6        NaN          NaN     NaN     1.0          NaN          EML1_001-Bias6  \n",
       "12       NaN          NaN     NaN     NaN          NaN  EML1_001-CausalClaims2  \n",
       "18       NaN          NaN     NaN     NaN          NaN  EML1_001-CausalClaims8  \n",
       "20       NaN          NaN     NaN     NaN          NaN    EML1_001-Hypotheses1  \n",
       "...      ...          ...     ...     ...          ...                     ...  \n",
       "7859     NaN          NaN     NaN     NaN          NaN    EML1_167-Hypotheses8  \n",
       "7860     NaN          NaN     NaN     NaN          NaN      EML1_167-Validity1  \n",
       "7864     NaN          NaN     NaN     NaN          NaN      EML1_167-Validity7  \n",
       "7869     NaN          NaN     NaN     NaN          NaN     EML1_167-Variables5  \n",
       "7871     NaN          NaN     NaN     NaN          NaN     EML1_167-Variables8  \n",
       "\n",
       "[1636 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[~label_df[\"Rote_X\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label columns for creating datasets\n",
    "label_cols = [\"Rote_X\", \"Inference_X\", \"Deep_X\", \"Rote_Y\", \"Inference_Y\", \"Rote_Z\", \"Inference_Z\", \"Deep_Z\", \"Rote_D\", \"Inference_D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(label_cols, label_df, data_folder, x_transforms=None, y_transforms=None, id_col=\"filename\"):\n",
    "    l_ds = []\n",
    "    for label_col in label_cols:\n",
    "        filenames = get_filenames_for_dataset(label_df, data_folder, id_col, label_col)\n",
    "        label_mapper = get_label_mapper(label_df, id_col, label_col)\n",
    "        ds = GazeDataModule(data_folder, file_list=filenames, label_mapper=label_mapper, transform_x=x_transforms, transform_y=y_transforms)\n",
    "        l_ds.append((label_col,ds))\n",
    "    return l_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ds = get_datasets([\"Rote_X\"], label_df, data_folder, x_transforms=[limit_sequence_len,lambda data: torch.tensor(data).float()], y_transforms=[lambda data: torch.tensor(data).float()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f.split(\".\")[0] for f in l_ds[0][1].file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Splits\n",
    "splits = get_stratified_group_splits(files, label_df, l_ds[0][0], \"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with one split\n",
    "train_split, val_split = next(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3,    5,    6,    7,    9,   10,   11,   13,   14,\n",
       "         15,   17,   18,   19,   21,   22,   23,   25,   26,   27,   29,\n",
       "         30,   31,   32,   34,   35,   37,   38,   39,   41,   42,   43,\n",
       "         45,   46,   47,   49,   50,   51,   53,   54,   55,   56,   58,\n",
       "         59,   61,   62,   63,   64,   65,   66,   69,   70,   71,   73,\n",
       "         74,   75,   76,   78,   79,   81,   82,   83,   84,   86,   87,\n",
       "         88,   90,   91,   93,   94,   95,   97,   98,   99,  100,  102,\n",
       "        103,  104,  106,  107,  109,  110,  111,  113,  114,  115,  117,\n",
       "        118,  119,  121,  122,  123,  125,  126,  127,  128,  130,  131,\n",
       "        132,  133,  135,  136,  138,  139,  141,  142,  143,  145,  146,\n",
       "        147,  148,  150,  151,  153,  154,  155,  157,  158,  159,  160,\n",
       "        162,  163,  165,  166,  167,  168,  170,  171,  173,  174,  175,\n",
       "        176,  178,  179,  181,  182,  183,  185,  186,  187,  189,  190,\n",
       "        191,  193,  194,  195,  197,  198,  199,  201,  202,  203,  205,\n",
       "        206,  207,  208,  210,  211,  213,  214,  215,  217,  218,  219,\n",
       "        221,  222,  223,  225,  226,  227,  229,  230,  231,  232,  234,\n",
       "        235,  237,  238,  239,  241,  242,  243,  245,  246,  247,  248,\n",
       "        249,  251,  253,  254,  255,  257,  258,  259,  260,  262,  263,\n",
       "        265,  266,  267,  269,  270,  271,  273,  274,  275,  277,  278,\n",
       "        279,  281,  282,  283,  285,  286,  287,  288,  290,  291,  293,\n",
       "        294,  295,  297,  298,  299,  301,  302,  303,  305,  306,  307,\n",
       "        308,  310,  311,  313,  314,  315,  316,  317,  319,  321,  322,\n",
       "        323,  324,  326,  327,  328,  330,  331,  332,  334,  335,  336,\n",
       "        338,  339,  341,  342,  343,  345,  346,  347,  349,  350,  351,\n",
       "        352,  354,  355,  356,  358,  359,  360,  362,  363,  365,  366,\n",
       "        367,  369,  370,  371,  372,  374,  375,  376,  377,  379,  380,\n",
       "        381,  383,  385,  386,  387,  388,  390,  391,  393,  394,  395,\n",
       "        397,  398,  399,  401,  402,  403,  404,  406,  407,  409,  410,\n",
       "        411,  413,  414,  415,  416,  418,  419,  421,  422,  423,  424,\n",
       "        426,  427,  428,  430,  431,  432,  433,  435,  436,  437,  439,\n",
       "        441,  442,  443,  445,  446,  447,  448,  450,  451,  453,  454,\n",
       "        455,  457,  458,  459,  461,  462,  463,  465,  466,  467,  469,\n",
       "        470,  471,  473,  474,  475,  476,  478,  479,  481,  482,  483,\n",
       "        485,  486,  487,  489,  490,  491,  492,  494,  495,  497,  498,\n",
       "        499,  501,  502,  503,  504,  506,  507,  508,  510,  511,  513,\n",
       "        514,  515,  516,  518,  519,  521,  522,  523,  525,  526,  527,\n",
       "        529,  530,  531,  533,  534,  535,  537,  538,  539,  540,  542,\n",
       "        543,  545,  546,  547,  548,  549,  551,  553,  554,  555,  557,\n",
       "        558,  559,  560,  562,  563,  564,  566,  567,  568,  570,  571,\n",
       "        572,  574,  575,  576,  578,  579,  581,  582,  583,  584,  586,\n",
       "        587,  589,  590,  591,  592,  593,  595,  597,  598,  599,  601,\n",
       "        602,  603,  605,  606,  607,  609,  610,  611,  613,  614,  615,\n",
       "        617,  618,  619,  621,  622,  623,  625,  626,  627,  629,  630,\n",
       "        631,  633,  634,  635,  636,  637,  639,  640,  641,  643,  644,\n",
       "        645,  647,  648,  649,  651,  653,  654,  655,  656,  657,  659,\n",
       "        661,  662,  663,  664,  666,  667,  668,  670,  671,  672,  674,\n",
       "        675,  677,  678,  679,  681,  682,  683,  685,  686,  687,  688,\n",
       "        690,  691,  693,  694,  695,  697,  698,  699,  700,  701,  703,\n",
       "        704,  705,  707,  708,  709,  710,  713,  714,  715,  716,  718,\n",
       "        719,  720,  722,  723,  724,  726,  727,  729,  730,  731,  733,\n",
       "        734,  735,  737,  738,  739,  741,  742,  743,  744,  746,  747,\n",
       "        748,  750,  751,  752,  754,  755,  757,  758,  759,  761,  762,\n",
       "        763,  765,  766,  767,  769,  770,  771,  773,  774,  775,  777,\n",
       "        778,  779,  781,  782,  783,  785,  786,  787,  788,  790,  791,\n",
       "        792,  793,  795,  796,  797,  799,  800,  801,  803,  805,  806,\n",
       "        807,  808,  810,  811,  813,  814,  815,  817,  818,  819,  821,\n",
       "        822,  823,  824,  826,  827,  829,  830,  831,  832,  834,  835,\n",
       "        837,  838,  839,  841,  842,  843,  845,  846,  847,  848,  850,\n",
       "        851,  853,  854,  855,  857,  858,  859,  861,  862,  863,  865,\n",
       "        866,  867,  869,  870,  871,  872,  874,  875,  876,  878,  879,\n",
       "        881,  882,  883,  884,  886,  887,  888,  890,  891,  892,  893,\n",
       "        895,  897,  898,  899,  900,  901,  903,  904,  906,  907,  908,\n",
       "        910,  911,  913,  914,  915,  917,  918,  919,  921,  922,  923,\n",
       "        925,  926,  927,  929,  930,  931,  933,  934,  935,  937,  938,\n",
       "        939,  940,  942,  943,  945,  946,  947,  949,  950,  951,  952,\n",
       "        953,  955,  956,  958,  959,  960,  962,  963,  964,  965,  967,\n",
       "        968,  970,  971,  972,  974,  975,  977,  978,  979,  981,  982,\n",
       "        983,  984,  985,  987,  988,  990,  991,  992,  994,  995,  997,\n",
       "        998,  999, 1001, 1002, 1003, 1004, 1006, 1007, 1008, 1010, 1011,\n",
       "       1012, 1014, 1015, 1016, 1017, 1019, 1021, 1022, 1023, 1025, 1026,\n",
       "       1027, 1029, 1030, 1031, 1032, 1034, 1035, 1036, 1038, 1039, 1041,\n",
       "       1042, 1043, 1044, 1046, 1047, 1048, 1050, 1051, 1053, 1054, 1055,\n",
       "       1057, 1058, 1059, 1061, 1062, 1063, 1065, 1066, 1067, 1069, 1070,\n",
       "       1071, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1082, 1083, 1084,\n",
       "       1085, 1087, 1089, 1090, 1091, 1092, 1094, 1095, 1096, 1097, 1098,\n",
       "       1101, 1102, 1103, 1105, 1106, 1107, 1109, 1110, 1111, 1112, 1114,\n",
       "       1115, 1116, 1117, 1119, 1120, 1121, 1123, 1124, 1125, 1127, 1128,\n",
       "       1129, 1130, 1132, 1133, 1134, 1136, 1137, 1138, 1140, 1141, 1142,\n",
       "       1144, 1145, 1147, 1148, 1150, 1151, 1153, 1154, 1155, 1157, 1158,\n",
       "       1159, 1161, 1162, 1163, 1165, 1166, 1167, 1169, 1170, 1171, 1172,\n",
       "       1174, 1175, 1176, 1178, 1179, 1181, 1182, 1183, 1185, 1186, 1187,\n",
       "       1189, 1190, 1191, 1192, 1194, 1195, 1197, 1198, 1199, 1201, 1202,\n",
       "       1203, 1205, 1206, 1207, 1209, 1210, 1211, 1213, 1214, 1215, 1217,\n",
       "       1218, 1219, 1221, 1222, 1223, 1224, 1226, 1227, 1228, 1230, 1231,\n",
       "       1232, 1234, 1235, 1236, 1237, 1239, 1240, 1242, 1243, 1245, 1246,\n",
       "       1247, 1249, 1250])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251 1251\n"
     ]
    }
   ],
   "source": [
    "# Setup datamodule\n",
    "dm = l_ds[0][1]\n",
    "dm.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataloader\n",
    "train_sampler = SubsetRandomSampler(train_split)\n",
    "train_dl = dm.train_dataloader(sampler=train_sampler)\n",
    "val_sampler = SubsetRandomSampler(val_split)\n",
    "val_dl = dm.val_dataloader(sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_weights_dir = Path(\"../trained_models/obf_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /Users/rickgentry/emotive_lab/eyemind/trained_models/obf_weights/encoder_1633040995_gru.pt\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained encoder\n",
    "encoder = creator.load_encoder(str(pre_trained_weights_dir.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickgentry/miniforge3/envs/cm2/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = EncoderClassifierModel(encoder, cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = Trainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | model           | Sequential        | 362 K \n",
      "1 | criterion       | BCEWithLogitsLoss | 0     \n",
      "2 | auroc_metric    | AUROC             | 0     \n",
      "3 | accuracy_metric | Accuracy          | 0     \n",
      "------------------------------------------------------\n",
      "362 K     Trainable params\n",
      "0         Non-trainable params\n",
      "362 K     Total params\n",
      "1.451     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickgentry/miniforge3/envs/cm2/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:659: UserWarning: Your `val_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/rickgentry/miniforge3/envs/cm2/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickgentry/miniforge3/envs/cm2/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/rickgentry/miniforge3/envs/cm2/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 69/156 [00:50<01:03,  1.37it/s, loss=nan, v_num=0, train_loss_step=0.766, train_accuracy_step=0.375, val_loss_step=0.692, val_accuracy_step=0.750, val_loss_epoch=0.693, val_accuracy_epoch=0.529, val_auroc=0.354, train_loss_epoch=0.750, train_accuracy_epoch=0.469, train_auroc=0.465] "
     ]
    }
   ],
   "source": [
    "# Find learning rate\n",
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1a371005750433fad728c36ce8654a34688417482f17f4469971f4dff2fd726"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cm2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
