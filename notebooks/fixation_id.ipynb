{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get percentage of fixations for us and for them AUPRC\n",
    "# Start at a fixed point\n",
    "# Shorten sequence length\n",
    "\n",
    "1. Results table \n",
    "2. Fine-tuning their model on fixations\n",
    "3. Regression \n",
    "4. Identify if it is the same text or participant\n",
    "4. Look at gaze papers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/dg/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import obf functionality\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"../../OBF\").resolve()))\n",
    "\n",
    "from eyemind.obf.model import ae\n",
    "from eyemind.obf.model import creator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyemind.dataloading.load_dataset import limit_sequence_len, get_label_mapper, get_filenames_for_dataset, create_filename_col, get_stratified_group_splits\n",
    "from eyemind.dataloading.gaze_data import GazeDataModule\n",
    "from eyemind.models.classifier import EncoderClassifierModel\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from pytorch_lightning import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"../data/processed/fixation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_label_mapper(files):\n",
    "    labels = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        label_array = df['fixation_label'].to_numpy(float)\n",
    "        labels.append(label_array)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_label_seq(y_data, sequence_length, pad_token=-1.):\n",
    "    if len(y_data) > sequence_length:\n",
    "        y_data = y_data[:sequence_length]\n",
    "    else:\n",
    "        pad_data = np.ones((sequence_length,)) * pad_token\n",
    "        pad_data[:len(y_data)] = y_data\n",
    "        y_data = pad_data\n",
    "    return y_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "sequence_len = 500\n",
    "lim_seq_len = partial(limit_sequence_len, sequence_len=sequence_len, random_part=False)\n",
    "limit_labels = partial(limit_label_seq, sequence_length=sequence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [lim_seq_len,lambda data: torch.tensor(data).float()]\n",
    "dm = GazeDataModule(data_folder, label_mapper=fixation_label_mapper, transform_x=transforms, transform_y=[limit_labels,lambda data: torch.tensor(data).float()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GazeDataModule' object has no attribute 'file_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dm\u001b[39m.\u001b[39;49msetup(stage\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Dropbox (Emotive Computing)/EML Rosy/DeepGaze/eyemind/dataloading/gaze_data.py:729\u001b[0m, in \u001b[0;36mGazeDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mif\u001b[39;00m stage \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    728\u001b[0m     \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dir \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \n\u001b[0;32m--> 729\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_test \u001b[39m=\u001b[39m SequenceLabelDataset(\u001b[39mdir\u001b[39m, file_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_list, label_mapper\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_mapper, transform_x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_x, transform_y\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_y, usecols\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols, skiprows\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskiprows)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GazeDataModule' object has no attribute 'file_list'"
     ]
    }
   ],
   "source": [
    "dm.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GazeDataModule.test_dataloader() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_dl \u001b[39m=\u001b[39m dm\u001b[39m.\u001b[39;49mtest_dataloader(shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: GazeDataModule.test_dataloader() got an unexpected keyword argument 'shuffle'"
     ]
    }
   ],
   "source": [
    "test_dl = dm.test_dataloader(shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XAvg   -39.506278\n",
      "YAvg   -25.359353\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from eyemind.preprocessing.standardizing import get_stats\n",
    "mean, std = get_stats(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = mean.tolist()\n",
    "std = std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.6983440282868998, -1.9408488122606675]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyemind.dataloading.transforms import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ss = StandardScaler(mean=mean,std=std)\n",
    "df = pd.read_csv(Path(data_folder,\"EML1_003-Hypotheses0.csv\"), usecols=[\"XAvg\", \"YAvg\"])\n",
    "data = df.to_numpy()\n",
    "standard_data = ss(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_data[standard_data==-180] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.21242255, 1.15307637])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanstd(standard_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fixation counts\n",
    "def count_fixation_percentage_folder(data_dir):\n",
    "    fixation_count = 0\n",
    "    total_labels = 0\n",
    "\n",
    "    for filepath in Path.glob(data_folder, \"*.csv\"):\n",
    "        df = pd.read_csv(filepath)\n",
    "        total_labels += len(df['fixation_label'])\n",
    "        fixation_count += df['fixation_label'].sum()\n",
    "    return fixation_count / total_labels, fixation_count, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(data_dir):\n",
    "    labels=[]\n",
    "\n",
    "    for filepath in Path.glob(data_folder, \"*.csv\"):\n",
    "        print(filepath)\n",
    "        df = pd.read_csv(filepath)\n",
    "        labels += df['fixation_label'].tolist()\n",
    "        # return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_perc, fix_count, total_labels = count_fixation_percentage_folder(data_folder)\n",
    "\n",
    "print(fix_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inv_ratios(fixation_count, total_labels):\n",
    "    inv_ratio_fix = 1 / (fixation_count / (total_labels - fixation_count))\n",
    "    inv_ratio_sacc = 1 / ((total_labels - fixation_count)/ fixation_count)\n",
    "    return inv_ratio_sacc, inv_ratio_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8618245366084953"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / ((total_labels - fix_count)/ fix_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25894495995880046"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (fix_count/ (total_labels - fix_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.8618245366084953, 0.25894495995880046)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_inv_ratios(fix_count, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_label_counts(dl):\n",
    "    total_labels = 0\n",
    "    fixation_count = 0\n",
    "    for _, labels in dl:\n",
    "        fixation_count += labels.sum().numpy()\n",
    "        total_labels += torch.numel(labels)\n",
    "    return fixation_count, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(data_folder):\n",
    "    _,fixation_count, total_labels = count_fixation_percentage_folder(data_folder)\n",
    "    inv_ratio_sacc, inv_ratio_fix = get_inv_ratios(fixation_count, total_labels)\n",
    "    inv_ratios = np.array([inv_ratio_sacc, inv_ratio_fix])\n",
    "    print(inv_ratios)\n",
    "    class_weights = inv_ratios / inv_ratios.sum()\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "def get_class_weights_from_dl(dl):\n",
    "    fixation_count, total_labels = fixation_label_counts(dl)\n",
    "    inv_ratio_sacc, inv_ratio_fix = get_inv_ratios(fixation_count, total_labels)\n",
    "    inv_ratios = np.array([inv_ratio_sacc, inv_ratio_fix])\n",
    "    print(inv_ratios)\n",
    "    class_weights = inv_ratios / inv_ratios.sum()\n",
    "    return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.86182454 0.25894496]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.93716102, 0.06283898])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_weights(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12232686"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights=class_weight.compute_class_weight('balanced',classes=np.unique(labels),y=np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.43091227, 0.62947248])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def plot_fix_signal(signal, labels):\n",
    "    sl = signal.shape[0]\n",
    "    x = signal[:,0]\n",
    "    y = signal[:,1]\n",
    "    labels = labels.astype(int)\n",
    "    label_colors ={0: 'green', 1: 'red'}\n",
    "    for l in np.unique(labels):\n",
    "        ix = np.where(labels == l)\n",
    "        plt.plot(list(range(sl)), x[ix], c = label_colors[l], label=l)\n",
    "        plt.plot(list(range(sl)), y[ix], c = label_colors[l], label=l)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyemind.obf.utils.signal_visualization import xy_t_fix_signal\n",
    "\n",
    "def visualize_random_example(dl, plot_fn, scale_fix=1):\n",
    "    for signals, labels in dl:\n",
    "        signal = signals[0].numpy()\n",
    "        label = labels[0].numpy() * scale_fix\n",
    "        plot_fn(signal, label)\n",
    "        break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.771588490882394\n",
      "17.088726202979693\n"
     ]
    }
   ],
   "source": [
    "from eyemind.preprocessing.signal_normalizing import get_pixels_per_degree, get_screen_limits\n",
    "\n",
    "# Stats of setup\n",
    "screen_res = (1920,1080)\n",
    "screen_size = (525.78,297.18)\n",
    "subject_dist = 989\n",
    "screen_center = (screen_res[0]//2,screen_res[1]//2)\n",
    "\n",
    "pixels_per_deg = get_pixels_per_degree(screen_res, screen_size, subject_dist)\n",
    "x_lims, y_lims = get_screen_limits(screen_res, pixels_per_deg)\n",
    "print(x_lims)\n",
    "print(y_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize_fix_signal(inputs, fixations, lims=(-10,10), title=\"Fixation ID Signal\"):\n",
    "\n",
    "    n1 = inputs.shape[0]\n",
    "    max_val = inputs.max()\n",
    "\n",
    "    # The input sequence\n",
    "    plt.plot(list(range(n1)),\n",
    "            inputs[:, 0],\n",
    "            label=\"x\",\n",
    "            color=\"orange\",\n",
    "            alpha=0.8)\n",
    "    plt.plot(list(range(n1)),\n",
    "            inputs[:, 1],\n",
    "            label=\"y\",\n",
    "            color=\"blue\",\n",
    "            alpha=0.8)\n",
    "\n",
    "    # The Ground truth sequence\n",
    "    saccade_gt_time = np.where(fixations == 0)[0]\n",
    "    plt.scatter(saccade_gt_time,\n",
    "                saccade_gt_time * 0,\n",
    "                label=\"GT Sac\",\n",
    "                color=\"green\",\n",
    "                alpha=0.2)\n",
    "    fix_gt_time = np.where(fixations == 1)[0]\n",
    "    plt.scatter(fix_gt_time,\n",
    "                np.ones((len(fix_gt_time),)) * max_val,\n",
    "                label=\"GT Fix\",\n",
    "                color=\"red\",\n",
    "                alpha=0.2)\n",
    "    plt.ylim(*lims)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m visualize_random_example(test_dl, vizualize_fix_signal)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dl' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_random_example(test_dl, vizualize_fix_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_signal_on_screen_with_fixations(\n",
    "                signal, \n",
    "                labels,\n",
    "                screen_width=29.77,\n",
    "                screen_height=17.09,\n",
    "                resolution_magnifier=10,\n",
    "                scatter_size = 5,\n",
    "                off_screen_factor = 2,\n",
    "                title=\"\"):\n",
    "  \"\"\"\n",
    "  \n",
    "  \n",
    "  Args:\n",
    "    signal: 2D signal\n",
    "    labels: 0 or 1 for saccade or fixation\n",
    "    screen_width: unit is visual degrees\n",
    "    screen_height: unit is visual degrees\n",
    "    resolution_magnifier (int): magnify visualization \n",
    "    \n",
    "  \"\"\"\n",
    "\n",
    "  # background image: * 2 for off-screen gazes\n",
    "  img = np.zeros((int(screen_height * off_screen_factor * resolution_magnifier), int(screen_width * off_screen_factor * resolution_magnifier), 3),\n",
    "                 dtype=np.float32)\n",
    "\n",
    "  for i,(x, y) in enumerate(signal):\n",
    "    xi = int(x * resolution_magnifier + screen_width * resolution_magnifier)\n",
    "    yi = int(y * resolution_magnifier + screen_height * resolution_magnifier)\n",
    "\n",
    "    try:\n",
    "      label = labels[i]\n",
    "      if label == 0:\n",
    "        img[yi - scatter_size:yi + scatter_size+1, xi - scatter_size:xi + scatter_size+1, 1] += 0.9\n",
    "      elif label == 1:\n",
    "        img[yi - scatter_size:yi + scatter_size+1, xi - scatter_size:xi + scatter_size+1, 0] += 0.9\n",
    "      else:\n",
    "        raise Exception(\"Label was not 0 or 1\")\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "\n",
    "  img = np.clip(img, 0, 1)\n",
    "  plt.imshow(img)\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_example_from_dataloader(dl):\n",
    "    x_batch, y_batch = next(iter(dl))\n",
    "    x, y = x_batch[0], y_batch[0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m signal, labels \u001b[39m=\u001b[39m get_random_example_from_dataloader(test_dl)\n\u001b[1;32m      2\u001b[0m show_signal_on_screen_with_fixations(signal, labels,resolution_magnifier\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,scatter_size\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, off_screen_factor\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dl' is not defined"
     ]
    }
   ],
   "source": [
    "signal, labels = get_random_example_from_dataloader(test_dl)\n",
    "show_signal_on_screen_with_fixations(signal, labels,resolution_magnifier=1,scatter_size=0, off_screen_factor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBF_RELPATH = \"../../OBF\"\n",
    "sys.path.append(str(Path(OBF_RELPATH).resolve()))\n",
    "from eyemind import obf\n",
    "\n",
    "pre_trained_weights_dir = Path(OBF_RELPATH + \"/pre_weights/sample_weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /Users/roso8920/Dropbox (Emotive Computing)/EML Rosy/OBF/pre_weights/sample_weights/encoder_1633040995_gru.pt\n"
     ]
    }
   ],
   "source": [
    "encoder = creator.load_encoder(str(pre_trained_weights_dir.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): CNNEncoder(\n",
      "    (cnn): Sequential(\n",
      "      (0): ConvBlock(\n",
      "        (conv): Conv1d(2, 14, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (pool_layer): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "        (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (conv): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): RNNEncoder(\n",
      "    (rnn): GRU(32, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_decoder = torch.load(str(Path(pre_trained_weights_dir, \"fi_1633040995_gru.pt\").resolve()),map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixationIdentifier(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = self.encoder(x)\n",
    "        output = self.decoder(embeddings)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_model = FixationIdentifier(encoder, fi_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixationIdentifier(\n",
      "  (encoder): Sequential(\n",
      "    (0): CNNEncoder(\n",
      "      (cnn): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (conv): Conv1d(2, 14, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "          (pool_layer): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "          (bn): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): LeakyReLU(negative_slope=0.01)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): RNNEncoder(\n",
      "      (rnn): GRU(32, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
      "    )\n",
      "  )\n",
      "  (decoder): RNNDecoder(\n",
      "    (rnn): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
      "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (out_fc): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(fid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(test_dl))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dl' is not defined"
     ]
    }
   ],
   "source": [
    "batch = next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fid_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 500, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.softmax(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logits.argmax(dim=2).detach().cpu().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logits.softmax(dim=2)[:,:,1].detach().cpu().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.cpu().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506709492371336"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73525"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import tqdm\n",
    "\n",
    "def evaluate(dl, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    for x, y in tqdm.tqdm(dl):\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(dim=2).detach().cpu().numpy().reshape(-1)\n",
    "        probs = logits.softmax(dim=2)[:,:,1].detach().cpu().numpy().reshape(-1)\n",
    "        y = y.cpu().numpy().reshape(-1)\n",
    "        all_preds += preds.tolist()\n",
    "        all_labels += y.tolist()\n",
    "        all_probs += probs.tolist()\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_preds = np.array(all_preds)\n",
    "    masked_indices = all_labels == -1\n",
    "    acc = metrics.accuracy_score(all_labels[~masked_indices], all_preds[~masked_indices])\n",
    "    auc = metrics.roc_auc_score(all_labels[~masked_indices], all_probs[~masked_indices])\n",
    "    return acc, auc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 784/784 [08:00<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, labels, probs = evaluate(test_dl, fid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(preds)\n",
    "acc = metrics.accuracy_score(labels[~indices_masked], preds[~indices_masked])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467187887901037"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(labels[~indices_masked], probs[~indices_masked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6525304778413941"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickgentry/miniforge3/envs/eyemind/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from eyemind.dataloading.gaze_data import BaseSequenceToSequenceDataModule\n",
    "from eyemind.dataloading.informer_data import InformerDataModule\n",
    "import torch\n",
    "\n",
    "def load_model_from_checkpoint(model_cls, checkpoint_path):\n",
    "    return model_cls.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "def get_dataloader(dataloader_cls, config_path, data_base_dir=\"./data\", label_filepath=\"processed/EML1_pageLevel_with_filename_seq.csv\", data_dir=\"processed/fixation\"):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    config[\"data\"][\"data_dir\"] = str(Path(data_base_dir, data_dir).resolve())\n",
    "    config[\"data\"][\"label_filepath\"] = str(Path(data_base_dir, label_filepath).resolve())\n",
    "    dm = dataloader_cls(**config['data'])\n",
    "    dm.setup()\n",
    "    return dm.predict_dataloader()\n",
    "\n",
    "def get_prediction_targets(model, dl, samples=1):\n",
    "    model.eval()\n",
    "    batch = next(iter(dl))\n",
    "    logits = model.forward(batch[0])\n",
    "    print(logits.shape)\n",
    "    fixation_preds = model._get_preds(logits)\n",
    "    print(fixation_preds.shape)\n",
    "    fixation_targets = batch[1]\n",
    "    rows = torch.randint(high=len(fixation_preds),size=(samples,))\n",
    "    return fixation_preds[rows].squeeze(), fixation_targets[rows].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eyemind.models.encoder_decoder import VariableSequenceLengthEncoderDecoderModel\n",
    "model = load_model_from_checkpoint(VariableSequenceLengthEncoderDecoderModel, \"./lightning_logs/fixation_seq500_200epochs/checkpoints/epoch=199-step=3400.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dataloader(BaseSequenceToSequenceDataModule,\"./lightning_logs/fixation_seq500_200epochs/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 500, 2])\n",
      "torch.Size([64, 500])\n"
     ]
    }
   ],
   "source": [
    "preds, targets = get_prediction_targets(model, dl,samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickgentry/miniforge3/envs/eyemind/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from eyemind.models.transformers import InformerEncoderFixationModel\n",
    "informer_model = load_model_from_checkpoint(InformerEncoderFixationModel, \"./lightning_logs/fixation_informer_seq500_epochs120/checkpoints/epoch=120-step=2057.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "informer_dl = get_dataloader(InformerDataModule ,\"./lightning_logs/fixation_informer_seq500_epochs120/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 500, 2])\n",
      "torch.Size([64, 500])\n"
     ]
    }
   ],
   "source": [
    "informer_preds, informer_targets = get_prediction_targets(informer_model, informer_dl, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 500]), torch.Size([4, 500]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_preds.shape,informer_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_figures(preds, targets):\n",
    "    num_plots = len(preds)\n",
    "    rows = (num_plots // 5) + 1\n",
    "    cols = 5\n",
    "    plt.figure(0)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = plt.subplot2grid((rows,cols), (i,j))\n",
    "            ax.step(np.arange(len(preds[0])),targets[j * i].numpy(), preds[j * i].numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m./notebooks/fixation_id.ipynb Cell 88\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:./notebooks/fixation_id.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_figures(preds, targets)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "plot_figures(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "def fixation_image(pred,target, title=\"Fixation Identification\"):\n",
    "    sl = len(pred)\n",
    "    fixation_labels = torch.cat((pred.expand(sl//2,sl),target.expand(sl//2,sl)))\n",
    "    plt.imshow(fixation_labels, extent=[0, len(fixation_labels[1]),0, 100], cmap='Greys')\n",
    "    # plt.xticks(np.arange(0, len(fixation_labels), 1), [])\n",
    "    plt.yticks([])\n",
    "    # plt.grid(True, axis='x', lw=1, c='black')\n",
    "    # plt.tick_params(axis='x', length=0)\n",
    "    plt.title(title)\n",
    "    black = mpatches.Patch(color='black', label='Fixation')\n",
    "    white = mpatches.Patch(color='white', label='Saccade')\n",
    "    plt.legend(handles=[black, white],bbox_to_anchor=(1.15, 1), loc='upper right')\n",
    "    plt.xlabel(\"Time Steps (100 steps ~ 1.7s)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixation_image(informer_preds[1], informer_targets[1], \"Fixation Identification - Informer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixation_image(preds[1], targets[1], \"Fixation Identification - RNN Encoder-Decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datamodule\n",
    "import yaml\n",
    "from eyemind.dataloading.gaze_data import BaseSequenceToSequenceDataModule\n",
    "config_path = \"./lightning_logs/version_11471837/config.yaml\"\n",
    "local_data_dir = \"./data/processed/fixation\"\n",
    "local_label_filepath = \"./data/processed/EML1_pageLevel_with_filename_seq.csv\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config[\"data\"][\"data_dir\"] = local_data_dir\n",
    "config[\"data\"][\"label_filepath\"] = local_label_filepath\n",
    "dm = BaseSequenceToSequenceDataModule(**config['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dl = dm.predict_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickgentry/miniforge3/envs/eyemind/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "config[\"trainer\"][\"accelerator\"] = \"cpu\"\n",
    "trainer = Trainer(**config[\"trainer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(predict_dl))\n",
    "preds = model.predict_step(batch, 0)\n",
    "fixation_preds = preds[\"fi\"]\n",
    "fixation_targets = batch[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "row = np.random.randint(0, len(fixation_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = fixation_preds[row], fixation_targets[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize_fix_signal(inputs, fixations, lims=(-10,10), title=\"Fixation ID Signal\"):\n",
    "\n",
    "    n1 = inputs.shape[0]\n",
    "    max_val = inputs.max()\n",
    "\n",
    "    # The input sequence\n",
    "    plt.plot(list(range(n1)),\n",
    "            inputs[:, 0],\n",
    "            label=\"x\",\n",
    "            color=\"orange\",\n",
    "            alpha=0.8)\n",
    "    plt.plot(list(range(n1)),\n",
    "            inputs[:, 1],\n",
    "            label=\"y\",\n",
    "            color=\"blue\",\n",
    "            alpha=0.8)\n",
    "\n",
    "    # The Ground truth sequence\n",
    "    saccade_gt_time = np.where(fixations == 0)[0]\n",
    "    plt.scatter(saccade_gt_time,\n",
    "                saccade_gt_time * 0,\n",
    "                label=\"GT Sac\",\n",
    "                color=\"green\",\n",
    "                alpha=0.2)\n",
    "    fix_gt_time = np.where(fixations == 1)[0]\n",
    "    plt.scatter(fix_gt_time,\n",
    "                np.ones((len(fix_gt_time),)) * max_val,\n",
    "                label=\"GT Fix\",\n",
    "                color=\"red\",\n",
    "                alpha=0.2)\n",
    "    plt.ylim(*lims)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1738c19d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "target.numpy()\n",
    "plt.step(np.arange(len(target)),target.numpy())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_fixation_len(fixations):\n",
    "    i = 0\n",
    "    fix_lens = []\n",
    "    while i < len(fixations):\n",
    "        if fixations[i]:\n",
    "            j = i\n",
    "            while j < len(fixations) and fixations[j]:\n",
    "                j+=1\n",
    "            fix_lens.append(j - i)\n",
    "            i = j\n",
    "        else: \n",
    "            i+= 1\n",
    "    if len(fix_lens) == 0:\n",
    "        return 500, 0\n",
    "    return sum(fix_lens) / len(fix_lens), len(fix_lens)\n",
    "\n",
    "def avg_saccade_len(fixations):\n",
    "    i = 0\n",
    "    saccade_lens = []\n",
    "    while i < len(fixations):\n",
    "        if fixations[i] == 0:\n",
    "            j = i\n",
    "            while j < len(fixations) and fixations[j] == 0:\n",
    "                j+=1\n",
    "            saccade_lens.append(j - i)\n",
    "            i = j\n",
    "        else: \n",
    "            i+= 1\n",
    "    return sum(saccade_lens) / len(saccade_lens), len(saccade_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.035714285714285, 30.161290322580644, 34.56666666666666, 57.31428571428572, 44.5, 62.33333333333333, 30.161290322580644, 136.0, 42.5, 68.48571428571428, 39.3125, 36.74193548387097, 35.94285714285714, 56.51351351351351, 91.47619047619048, 30.174999999999997, 38.371428571428574, 68.53125, 43.714285714285715, 35.36, 55.935483870967744, 29.363636363636363, 62.33333333333333, 32.62162162162162, 55.935483870967744, 221.0, 38.13513513513514, 39.5, 27.685714285714287, 34.54838709677419, 32.62162162162162, 36.91428571428571, 26.633333333333333, 33.56410256410257, 33.028571428571425, 43.27272727272727, 49.82758620689655, 39.84375, 28.609756097560975, 38.146341463414636, 65.65517241379311, 240.0, 30.161290322580644, 36.17948717948718, 56.230769230769226, 63.628571428571426, 43.714285714285715, 70.61538461538463, 72.25, 349.5625, 51.0, 45.769230769230774, 30.5, 44.766666666666666, 41.93333333333334, 51.58620689655172, 34.91891891891892, 42.282051282051285, 46.21875, 99.38461538461537, 102.65384615384615, 65.16666666666667, 29.87878787878788, 55.63636363636364]\n"
     ]
    }
   ],
   "source": [
    "saccade_lens = []\n",
    "for s in fixation_targets:\n",
    "    saccade_lens.append(avg_saccade_len(s)*17)\n",
    "print(saccade_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 6, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 10, 1, 1, 5, 1, 1, 1, 6, 1, 1, 1, 0, 3, 28, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "avg_fixations = []\n",
    "for s in fixation_preds:\n",
    "    avg_fixations.append(avg_fixation_len(s)[1])\n",
    "print(avg_fixations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 32, 31, 34, 34, 28, 32, 22, 34, 35, 33, 31, 36, 38, 22, 40, 35, 33, 29, 26, 32, 23, 27, 37, 32, 19, 38, 34, 36, 32, 38, 36, 30, 40, 36, 33, 30, 31, 41, 42, 30, 17, 32, 39, 39, 34, 29, 26, 29, 15, 30, 40, 34, 31, 31, 29, 38, 40, 33, 27, 27, 37, 33, 34]\n"
     ]
    }
   ],
   "source": [
    "num_fix = []\n",
    "for s in fixation_targets:\n",
    "    num_fix.append(avg_fixation_len(s)[1])\n",
    "print(num_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fixation_len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAAPCAYAAADatBV3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAeElEQVR4nO3bIQ7EMAxFQXu1Vyju/Y+1vHfw8qokUtUPOgOtAKMHoqRnpgB43ie9AMBbCTBAiAADhAgwQIgAA4QIMEDId+Vwd3uzBrDumJntPFwKcFUdVfW7Zx+A19ivhu0jBkCGO2CAEAEGCBFggBABBggRYICQP39jDQd05e+4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#target = target.numpy()\n",
    "plt.imshow(target.reshape(1, -1), extent=[0, len(target), 0, 1], cmap='Greys')\n",
    "plt.xticks(np.arange(0, len(target), 1), [])\n",
    "plt.yticks([])\n",
    "plt.grid(True, axis='x', lw=1, c='black')\n",
    "plt.tick_params(axis='x', length=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('eyemind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27febf39bfd259f69c2e36f15f94770a6426a2d8848f91fec23f21f64f7a227c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
