{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tbparse import SummaryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE='informer' # GRU or informer\n",
    "SAVE_PATH = f\"../results/ICMI24_{MODEL_TYPE}_results.md\"\n",
    "SEED=21\n",
    "OVERWRITE=True\n",
    "if OVERWRITE:\n",
    "     open(SAVE_PATH, 'w').close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_results_from_eventfile(dirpath, metrics, SAVE_PATH=\"\", title=\"\", select=\"latest\"):\n",
    "    # select = \"latest\", or \"lowest\" or \"highest\"\n",
    "    reader = SummaryReader(dirpath, pivot=False, extra_columns={'dir_name'})\n",
    "    df = reader.scalars\n",
    "    df = df.rename(columns={\"tag\": \"metric\", \"dir_name\": \"fold\"})\n",
    "    grouped = df.groupby([\"fold\",\"metric\"])\n",
    "    # ['step'].max().reset_index() # this is choosing the max AUROC but we want the latest!!\n",
    "    if select=='latest':\n",
    "        df = df.loc[grouped['step'].idxmax()].reset_index(drop=True)\n",
    "    elif select=='highest':\n",
    "        df = df.loc[grouped['value'].idxmax()].reset_index(drop=True)\n",
    "    elif select=='lowest':\n",
    "        df = df.loc[grouped['value'].idxmin()].reset_index(drop=True)\n",
    "    \n",
    "    df = df[df[\"metric\"].isin(metrics)].set_index([\"fold\"]).sort_values(\"metric\").reset_index()\n",
    "\n",
    "    res = df.pivot(index='fold', columns='metric', values='value')#.rename_axis(columns=None)\n",
    "    if SAVE_PATH:\n",
    "        with open(SAVE_PATH,'a') as f:\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(title)\n",
    "            f.write(\"\\n\")\n",
    "        res.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=True,floatfmt='.3f')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get pretraining task val metrics \n",
    "tasks=['fi','cl','pc','rc']\n",
    "metric_names=['FI: AUROC','CL: Accuracy','PC: MSE (deg)','RC: MSE (deg)']\n",
    "metric_select=['highest','highest','lowest','lowest'] # which value to use when multiple checkpoints avail\n",
    "varname = 'val_{task}_metric'\n",
    "metrics=[varname.format(**locals()) for task in tasks]\n",
    "\n",
    "pretrain_summary=[]\n",
    "for i,metric in enumerate(metrics):\n",
    "    name=metric_names[i]\n",
    "    res=get_metric_results_from_eventfile(f\"../lightning_logs/2023/{MODEL_TYPE}_pretraining_seed{SEED}\", [metric], SAVE_PATH=None, title=name, select=\"latest\")\n",
    "    pretrain_summary.append({\"metric\":name, \n",
    "                       \"mean\": res[[metric]].mean().item(),\n",
    "                       \"min\": res[[metric]].min().item(),\n",
    "                       \"max\": res[[metric]].max().item()\n",
    "                       })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "tit=\"Pretraining validation metrics: summarized\"\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(tit)\n",
    "    f.write(\"\\n\")\n",
    "tb = pd.DataFrame.from_records(pretrain_summary)\n",
    "tb.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=False,floatfmt='.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['SVT',\n",
    "'Rote_X', 'Rote_Y', \"Rote_Z\", \"Rote_D\",\n",
    "          'Inference_X', \"Inference_Y\",\"Inference_Z\", \"Inference_D\", \n",
    "          \"Deep_X\", \"Deep_Z\",\n",
    "          \"MW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"train_auroc\", \"val_auroc\", \"train_accuracy_epoch\", \"val_accuracy_epoch\"]\n",
    "val_aurocs = []\n",
    "tit=f\"Held-out AUROCs: informer with fixed sequence length 500\"\n",
    "\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(tit)\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "for label in labels:\n",
    "    # if label=='SVT':\n",
    "    #     continue\n",
    "    res=get_metric_results_from_eventfile(f\"../lightning_logs/2023/informer_{label}\", metrics, SAVE_PATH=None, select=\"latest\")\n",
    "    res['label']=label\n",
    "    val_aurocs.append({\"label\":label, \n",
    "                       \"mean AUROC\": res[['val_auroc']].mean().item(),\n",
    "                       \"min AUROC\": res[['val_auroc']].min().item(),\n",
    "                       \"max AUROC\": res[['val_auroc']].max().item()\n",
    "                       })\n",
    "tb = pd.DataFrame.from_records(val_aurocs)\n",
    "tb_oldres = tb[['label','mean AUROC']]\n",
    "tb_oldres.set_index('label', inplace=True)\n",
    "tb.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=False,floatfmt='.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"train_auroc\", \"val_auroc\", \"train_accuracy_epoch\", \"val_accuracy_epoch\"]\n",
    "classifier_names = ['informer_4task_encoder_varlen_meanpool', 'informer_4task_encoder_varlen_maskmeanpool','informer_4task_encoder_varlen_finalpos',\n",
    "'limu_125', 'limu_125_masked','limu_125_finalpos']\n",
    "mean_aurocs=[]\n",
    "for classifier in classifier_names:\n",
    "    val_aurocs = []\n",
    "    MODEL_TYPE='limu' if 'limu' in classifier else 'informer'\n",
    "    for label in labels:\n",
    "        # tit=f\"# {label}\"\n",
    "        # with open(SAVE_PATH, \"a\") as f:\n",
    "        #     f.write(\"\\n\\n\")\n",
    "        #     f.write(tit)\n",
    "        #     f.write(\"\\n\")\n",
    "        res=get_metric_results_from_eventfile(f\"../lightning_logs/2024/classifiers/{classifier}/{label}_{MODEL_TYPE}\", metrics, SAVE_PATH=None, select=\"latest\")\n",
    "        res['label']=label\n",
    "        val_aurocs.append({\"label\":label, \n",
    "                        \"mean AUROC\": res[['val_auroc']].mean().item(),\n",
    "                        \"min AUROC\": res[['val_auroc']].min().item(),\n",
    "                        \"max AUROC\": res[['val_auroc']].max().item()\n",
    "                        })\n",
    "        mean_aurocs.append({\"label\":label, \"classifier\":classifier, \"mean AUROC\": res[['val_auroc']].mean().item()})\n",
    "    tit=f\"Held-out AUROCs: {classifier}\"\n",
    "    with open(SAVE_PATH, \"a\") as f:\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(tit)\n",
    "        f.write(\"\\n\")\n",
    "    tb = pd.DataFrame.from_records(val_aurocs)\n",
    "    tb.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=False,floatfmt='.3f')\n",
    "\n",
    "tb_all = pd.DataFrame.from_records(mean_aurocs)\n",
    "# add result for old result\n",
    "tb_all = tb_all.pivot(index='label', columns='classifier', values='mean AUROC')\n",
    "# transpose to have label in  columns and one row per classifier\n",
    "tb_all = tb_all.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_all = pd.DataFrame.from_records(mean_aurocs)\n",
    "tb_all = tb_all.pivot(index='label', columns='classifier', values='mean AUROC')\n",
    "tb_oldres = pd.DataFrame(tb_oldres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = tb_all.merge(tb_oldres, how='inner', left_index=True, right_index=True)\n",
    "# .reindex(labels)\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "classifier_names = ['informer_4task_encoder_varlen_meanpool', 'informer_4task_encoder_varlen_maskmeanpool','informer_4task_encoder_varlen_finalpos',\n",
    "'limu_125', 'limu_125_masked','limu_125_finalpos']\n",
    "merged_df.rename(columns={'mean AUROC': 'informer_fixlen', 'informer_4task_encoder_varlen_meanpool':'informer_meanpool','informer_4task_encoder_varlen_maskmeanpool':'informer_maskmeanpool','informer_4task_encoder_varlen_finalpos':'informer_finalpos','limu_125':'limu','limu_125_masked':'limu_masked','limu_125_finalpos':'limu_finalpos'}, inplace=True)\n",
    "cols = list(merged_df.columns)\n",
    "cols.insert(0, cols.pop(cols.index('informer_fixlen')))\n",
    "merged_df = merged_df.loc[:, cols]\n",
    "with open(SAVE_PATH, \"a\") as f:\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"# OVERALL RESULTS\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"mean AUROC over folds per classifier\")\n",
    "merged_df.to_markdown(SAVE_PATH, mode=\"a\", tablefmt=\"github\", index=True,floatfmt='.3f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyemind_arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1499b27fd6353fe811f6c3b1d5c11b5c4e6658fe4f557f45649495283ca3391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
